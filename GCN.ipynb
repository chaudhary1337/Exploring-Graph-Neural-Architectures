{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a2950b0012f430687deb46f035f730d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c50039b018424093b6500c3402633328",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea0b9f51a80740a889ca60b40550e5f8",
              "IPY_MODEL_f576bb45f2fe4d5f9f899e3d8acb412b",
              "IPY_MODEL_ae7735fe21134590a6a9379d590b9ca3"
            ]
          }
        },
        "c50039b018424093b6500c3402633328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea0b9f51a80740a889ca60b40550e5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ddda74f2b0554568b45d2da367a0c52b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aff48024d17042ee8e2c963fc12a97a7"
          }
        },
        "f576bb45f2fe4d5f9f899e3d8acb412b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed8c3da71a8a4291a45681241f95905a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb730483507643e1a168be14d0248cf3"
          }
        },
        "ae7735fe21134590a6a9379d590b9ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d738d6168e440a7879e1a3cb710dd34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [01:54&lt;00:00,  1.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9b4e52317c04f6bbac2670840c5f750"
          }
        },
        "ddda74f2b0554568b45d2da367a0c52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aff48024d17042ee8e2c963fc12a97a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed8c3da71a8a4291a45681241f95905a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb730483507643e1a168be14d0248cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d738d6168e440a7879e1a3cb710dd34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9b4e52317c04f6bbac2670840c5f750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goE7ICkpuuoz"
      },
      "source": [
        "*Note: With the current version of Torch, only CPU is availabe for geometric.*\n",
        "\n",
        "This directory contains the a selection of the Cora dataset (www.research.whizbang.com/data).\n",
        "\n",
        "The Cora dataset consists of Machine Learning papers. These papers are classified into one of the following seven classes:\n",
        "\t\tCase_Based\n",
        "\t\tGenetic_Algorithms\n",
        "\t\tNeural_Networks\n",
        "\t\tProbabilistic_Methods\n",
        "\t\tReinforcement_Learning\n",
        "\t\tRule_Learning\n",
        "\t\tTheory\n",
        "\n",
        "The papers were selected in a way such that in the final corpus every paper cites or is cited by atleast one other paper. There are 2708 papers in the whole corpus. \n",
        "\n",
        "After stemming and removing stopwords we were left with a vocabulary of size 1433 unique words. All words with document frequency less than 10 were removed.\n",
        "\n",
        "\n",
        "THE DIRECTORY CONTAINS TWO FILES:\n",
        "\n",
        "The .content file contains descriptions of the papers in the following format:\n",
        "\n",
        "\t\t<paper_id> <word_attributes>+ <class_label>\n",
        "\n",
        "The first entry in each line contains the unique string ID of the paper followed by binary values indicating whether each word in the vocabulary is present (indicated by 1) or absent (indicated by 0) in the paper. Finally, the last entry in the line contains the class label of the paper.\n",
        "\n",
        "The .cites file contains the citation graph of the corpus. Each line describes a link in the following format:\n",
        "\n",
        "\t\t<ID of cited paper> <ID of citing paper>\n",
        "\n",
        "Each line contains two paper IDs. The first entry is the ID of the paper being cited and the second ID stands for the paper which contains the citation. The direction of the link is from right to left. If a line is represented by \"paper1 paper2\" then the link is \"paper2->paper1\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0UDDgS1R5He",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828e6339-afce-4f89-ad93-42780ce86966"
      },
      "source": [
        "%%shell\n",
        "\n",
        "wget \"https://web.archive.org/web/20150918182409/http://www.cs.umd.edu/~sen/lbc-proj/data/cora.tgz\"\n",
        "tar -xzvf cora.tgz\n",
        "\n",
        "pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cpu.html\n",
        "pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cpu.html\n",
        "pip install torch-geometric\n",
        "\n",
        "pip install networkx\n",
        "\n",
        "pip install icecream\n",
        "pip install tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-19 15:07:29--  https://web.archive.org/web/20150918182409/http://www.cs.umd.edu/~sen/lbc-proj/data/cora.tgz\n",
            "Resolving web.archive.org (web.archive.org)... 207.241.237.3\n",
            "Connecting to web.archive.org (web.archive.org)|207.241.237.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘cora.tgz’\n",
            "\n",
            "cora.tgz                [ <=>                ] 163.15K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-11-19 15:07:30 (1.21 MB/s) - ‘cora.tgz’ saved [167063]\n",
            "\n",
            "cora/\n",
            "cora/README\n",
            "cora/cora.content\n",
            "cora/cora.cites\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcpu/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (291 kB)\n",
            "\u001b[K     |████████████████████████████████| 291 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cpu.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcpu/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (639 kB)\n",
            "\u001b[K     |████████████████████████████████| 639 kB 690 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.2.tar.gz (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.0.2-py3-none-any.whl (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.2-py3-none-any.whl size=535570 sha256=1d94b821bec52c1eef156c6cb88f8e193f5cb52ead16863597f6768488fe4eef\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/08/13/2321517088bb2e95bfd0e45033bb9c923189e5b2078e0be4ef\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 rdflib-6.0.2 torch-geometric-2.0.2 yacs-0.1.8\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (2.6.3)\n",
            "Collecting icecream\n",
            "  Downloading icecream-2.1.1-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-0.8.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.0.5 colorama-0.4.4 executing-0.8.2 icecream-2.1.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS3nxnvgqRJ8",
        "outputId": "f0846ddb-2202-4276-cf04-241ac54b3461"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from icecream import ic\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_geometric\n",
        "import networkx as nx\n",
        "import scipy\n",
        "from tqdm.notebook import tqdm   \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"CUDA Present:\", torch.cuda.is_available())\n",
        "print(\"CUDA Version:\", torch.version.cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 1.10.0+cu111\n",
            "CUDA Present: False\n",
            "CUDA Version: 11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayA3tFM3_c6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50922cf5-a61b-4922-d379-450871493966"
      },
      "source": [
        "CONFIG = {\n",
        "    'PATH': './cora',\n",
        "    'LIMIT': 20,\n",
        "    'HIDDEN_CHANNELS': 1024,\n",
        "    'NUM_LAYERS': 2,\n",
        "    'DROPOUT_RATE': 0,\n",
        "    'EPOCHS': 200\n",
        "}\n",
        "\n",
        "print(\"Here's the configuration: \")\n",
        "for k, v in CONFIG.items():\n",
        "    print(f\"{k} = {v}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the configuration: \n",
            "PATH = ./cora\n",
            "LIMIT = 20\n",
            "HIDDEN_CHANNELS = 1024\n",
            "NUM_LAYERS = 2\n",
            "DROPOUT_RATE = 0\n",
            "EPOCHS = 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KivNXrSJIai"
      },
      "source": [
        "class Data:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "    \n",
        "    def readFile(self, path):\n",
        "        lines = []\n",
        "        with open(path) as file:\n",
        "            lines = file.readlines()\n",
        "        return lines\n",
        "\n",
        "    def readContent(self, data):\n",
        "        nodes, labels, x = [], [], []\n",
        "        for d in data:\n",
        "            words = d.split(\"\\t\")\n",
        "            nodes.append(words[0].strip())\n",
        "            labels.append(words[-1].strip())\n",
        "            x.append([ord(w) - 48 for w in words[1:-1]])\n",
        "            # x.append(words[1:-1])\n",
        "\n",
        "        # ic(x[0])\n",
        "        LE = LabelEncoder()\n",
        "        labels = LE.fit_transform(labels)\n",
        "        ic(labels)\n",
        "        x_req = torch.Tensor(x)\n",
        "        # ic(x.shape)\n",
        "        x = pd.DataFrame.from_records(x)\n",
        "        \n",
        "        return nodes, labels, LE, x_req, x\n",
        "\n",
        "    def getLabels(self, LE, data):\n",
        "        return LE.inverse_transform(data)\n",
        "\n",
        "    def readCites(self, data):\n",
        "        edges = []\n",
        "        for d in data:\n",
        "            words = d.split(\"\\t\")\n",
        "            edges.append([\n",
        "                words[0].strip(),\n",
        "                words[1].strip()\n",
        "            ])\n",
        "        return edges\n",
        "\n",
        "    def splitDataCount(self, data, labels):\n",
        "        lcounter = dict((l, 0) for l in labels)\n",
        "        indices = []\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            if lcounter[label] < CONFIG['LIMIT']:\n",
        "                indices.append(i)\n",
        "                lcounter[label] += 1\n",
        "        rest = [x for x in range(len(labels)) if x not in indices]\n",
        "        # rest = random.sample(rest, 1000)\n",
        "        indices = torch.LongTensor(indices)\n",
        "        rest = torch.LongTensor(rest)\n",
        "        return indices, rest\n",
        "\n",
        "    def normalizeMatrix(self, A):\n",
        "        return scipy.sparse.diags(np.array(A.sum(1)).flatten() ** -1).dot(A)\n",
        "\n",
        "    def toTensor(self, A):\n",
        "        A = A.tocoo()\n",
        "        i = torch.tensor(np.vstack((A.row, A.col)), dtype=torch.long)\n",
        "        v = torch.tensor(A.data, dtype=torch.float)\n",
        "        return torch.sparse_coo_tensor(i, v, torch.Size(A.shape))\n",
        "\n",
        "    def buildGraph(self):\n",
        "        nodes, edges = self.getGraph()\n",
        "        G = nx.Graph()\n",
        "        G.add_nodes_from(nodes)\n",
        "        G.add_edges_from(edges)\n",
        "        A = nx.adjacency_matrix(G)\n",
        "        I = scipy.sparse.identity(A.shape[0])\n",
        "        A = A + I\n",
        "        A = self.normalizeMatrix(A)\n",
        "        A = self.toTensor(A)\n",
        "        ic(A.shape)\n",
        "        ic(nx.info(G))\n",
        "        return A, G\n",
        "\n",
        "    def getIndices(self):\n",
        "        return self.train, self.test\n",
        "\n",
        "    def getGraph(self):\n",
        "        return self.nodes, self.edges\n",
        "\n",
        "    def getMatrix(self):\n",
        "        return self.A\n",
        "\n",
        "    def getXY(self):\n",
        "        return self.x, torch.LongTensor(self.labels)\n",
        "\n",
        "    def printData(self):\n",
        "        print(f\"Number of nodes: {len(self.nodes)}\")\n",
        "        print(f\"Number of features per node: {len(self.x[0])}\")\n",
        "        print(f\"Categories: {set(self.labels)}\")\n",
        "\n",
        "    def handle(self):\n",
        "        data = self.readFile(self.path + '/cora.content')\n",
        "        e_data = self.readFile(self.path + '/cora.cites')\n",
        "        self.nodes, self.labels, self.LE, self.x, self.split = self.readContent(data)\n",
        "        self.train, self.test = self.splitDataCount(self.split, self.labels)\n",
        "        self.edges = self.readCites(e_data)\n",
        "        self.A, self.G = self.buildGraph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrMJTP4UF5PY"
      },
      "source": [
        "class MyGCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \"\"\"\n",
        "        in_channels: #features in the input\n",
        "        out_channels: #features in the output\n",
        "\n",
        "        these layers have their *own* independent weights and biases\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        self.W = nn.Parameter(torch.empty(in_channels, out_channels))\n",
        "        nn.init.xavier_uniform_(self.W)\n",
        "        self.b = nn.Parameter(torch.zeros(out_channels))\n",
        "\n",
        "    def forward(self, X, A):\n",
        "        \"\"\"\n",
        "        does the neat math on *symmetrically normalized* A\n",
        "        \"\"\"\n",
        "        a = torch.mm(X, self.W)\n",
        "        b = torch.spmm(A, a)\n",
        "        return b + self.b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-ENeltKMoa-"
      },
      "source": [
        "class MyGCN(nn.Module):\n",
        "    def __init__(\n",
        "            self, \n",
        "            in_channels, \n",
        "            hidden_channels, \n",
        "            num_layers, \n",
        "            out_channels, \n",
        "            dropout_rate\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.num_layers = num_layers\n",
        "        self.out_channels = out_channels\n",
        "        self.dropout_rate = dropout_rate\n",
        "        \n",
        "        self.MyGCNLayers = []\n",
        "        self.MyGCNLayers.append(\n",
        "            MyGCNLayer(self.in_channels, self.hidden_channels)\n",
        "        )\n",
        "        self.outputLayers = MyGCNLayer(self.hidden_channels, self.out_channels)\n",
        "\n",
        "        for _ in range(1, self.num_layers):\n",
        "            self.MyGCNLayers.append(\n",
        "                MyGCNLayer(self.hidden_channels, self.hidden_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, X, A):\n",
        "        \"\"\"\n",
        "        math done on *symmetrically normalized* A\n",
        "        \"\"\"\n",
        "        for layer in range(self.num_layers):\n",
        "            # forwarded to the *appropriate* MyGCNLayer\n",
        "            X = self.MyGCNLayers[layer].forward(X, A)\n",
        "            X = F.relu(X)\n",
        "            X = F.dropout(X, p=self.dropout_rate, training=self.training)\n",
        "        X = self.outputLayers.forward(X, A)\n",
        "        return F.log_softmax(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvmo2v5zJ0zR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb495bb-9ce9-4e91-cb96-b6962adcf1b4"
      },
      "source": [
        "dataset = Data(CONFIG['PATH'])\n",
        "dataset.handle()\n",
        "X, y = dataset.getXY()\n",
        "train, test = dataset.getIndices()\n",
        "ic(X.shape, y.shape)\n",
        "ic(train.shape, test.shape)\n",
        "\n",
        "A = dataset.getMatrix()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| labels: array([2, 5, 4, ..., 1, 0, 2])\n",
            "ic| A.shape: torch.Size([2708, 2708])\n",
            "ic| nx.info(G): 'Graph with 2708 nodes and 5278 edges'\n",
            "ic| X.shape: torch.Size([2708, 1433]), y.shape: torch.Size([2708])\n",
            "ic| train.shape: torch.Size([140]), test.shape: torch.Size([1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBdjPpkeJvH4"
      },
      "source": [
        "model = MyGCN(\n",
        "    in_channels=X.shape[1],\n",
        "    hidden_channels=CONFIG['HIDDEN_CHANNELS'],\n",
        "    num_layers=CONFIG['NUM_LAYERS'],\n",
        "    out_channels=7,\n",
        "    dropout_rate=CONFIG['DROPOUT_RATE']\n",
        ")\n",
        "\n",
        "loss = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "0a2950b0012f430687deb46f035f730d",
            "c50039b018424093b6500c3402633328",
            "ea0b9f51a80740a889ca60b40550e5f8",
            "f576bb45f2fe4d5f9f899e3d8acb412b",
            "ae7735fe21134590a6a9379d590b9ca3",
            "ddda74f2b0554568b45d2da367a0c52b",
            "aff48024d17042ee8e2c963fc12a97a7",
            "ed8c3da71a8a4291a45681241f95905a",
            "bb730483507643e1a168be14d0248cf3",
            "6d738d6168e440a7879e1a3cb710dd34",
            "b9b4e52317c04f6bbac2670840c5f750"
          ]
        },
        "id": "xVKG1zytqrv_",
        "outputId": "77e0f0fd-0939-4d6f-a710-795958f12d04"
      },
      "source": [
        "losses = []\n",
        "for _ in tqdm(range(CONFIG['EPOCHS'])):\n",
        "    optimizer.zero_grad()\n",
        "    output = model.forward(X, A)\n",
        "    train_x = torch.index_select(output, 0, train)\n",
        "    train_y = torch.index_select(y, 0, train)\n",
        "    l = loss(train_x, train_y)\n",
        "    l.backward()\n",
        "    losses.append(l.item())\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a2950b0012f430687deb46f035f730d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV5YiQJ_rFAM",
        "outputId": "038aaf5e-6df2-46ed-d199-6a6428223f9e"
      },
      "source": [
        "losses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9416035413742065,\n",
              " 1.8918306827545166,\n",
              " 1.8432536125183105,\n",
              " 1.7955442667007446,\n",
              " 1.7486099004745483,\n",
              " 1.7024567127227783,\n",
              " 1.657133936882019,\n",
              " 1.6127026081085205,\n",
              " 1.5692163705825806,\n",
              " 1.5267143249511719,\n",
              " 1.4852229356765747,\n",
              " 1.4447592496871948,\n",
              " 1.4053369760513306,\n",
              " 1.3669685125350952,\n",
              " 1.3296667337417603,\n",
              " 1.2934414148330688,\n",
              " 1.2582987546920776,\n",
              " 1.224238395690918,\n",
              " 1.1912541389465332,\n",
              " 1.1593350172042847,\n",
              " 1.128466248512268,\n",
              " 1.0986305475234985,\n",
              " 1.0698095560073853,\n",
              " 1.0419834852218628,\n",
              " 1.0151307582855225,\n",
              " 0.989228367805481,\n",
              " 0.9642512798309326,\n",
              " 0.9401729106903076,\n",
              " 0.9169657826423645,\n",
              " 0.894602358341217,\n",
              " 0.8730552792549133,\n",
              " 0.8522971868515015,\n",
              " 0.8323013186454773,\n",
              " 0.8130406737327576,\n",
              " 0.7944879531860352,\n",
              " 0.7766167521476746,\n",
              " 0.7594007253646851,\n",
              " 0.7428139448165894,\n",
              " 0.7268312573432922,\n",
              " 0.7114283442497253,\n",
              " 0.6965811848640442,\n",
              " 0.6822671294212341,\n",
              " 0.668463408946991,\n",
              " 0.6551485061645508,\n",
              " 0.6423014402389526,\n",
              " 0.6299020648002625,\n",
              " 0.6179308295249939,\n",
              " 0.606369137763977,\n",
              " 0.5951988697052002,\n",
              " 0.5844030380249023,\n",
              " 0.5739650130271912,\n",
              " 0.5638691782951355,\n",
              " 0.5541002750396729,\n",
              " 0.5446439981460571,\n",
              " 0.5354865193367004,\n",
              " 0.5266147255897522,\n",
              " 0.51801598072052,\n",
              " 0.5096784830093384,\n",
              " 0.5015907287597656,\n",
              " 0.49374204874038696,\n",
              " 0.48612192273139954,\n",
              " 0.47872069478034973,\n",
              " 0.47152888774871826,\n",
              " 0.4645378589630127,\n",
              " 0.4577391445636749,\n",
              " 0.45112448930740356,\n",
              " 0.44468650221824646,\n",
              " 0.438417911529541,\n",
              " 0.4323117434978485,\n",
              " 0.4263615608215332,\n",
              " 0.4205612242221832,\n",
              " 0.41490471363067627,\n",
              " 0.409386545419693,\n",
              " 0.4040013551712036,\n",
              " 0.3987441062927246,\n",
              " 0.39361000061035156,\n",
              " 0.38859447836875916,\n",
              " 0.38369321823120117,\n",
              " 0.3789021670818329,\n",
              " 0.3742172420024872,\n",
              " 0.3696348965167999,\n",
              " 0.3651515543460846,\n",
              " 0.3607637584209442,\n",
              " 0.35646843910217285,\n",
              " 0.352262407541275,\n",
              " 0.3481428027153015,\n",
              " 0.34410685300827026,\n",
              " 0.34015193581581116,\n",
              " 0.33627548813819885,\n",
              " 0.33247509598731995,\n",
              " 0.3287484347820282,\n",
              " 0.32509341835975647,\n",
              " 0.3215077519416809,\n",
              " 0.3179895281791687,\n",
              " 0.3145368695259094,\n",
              " 0.3111478388309479,\n",
              " 0.30782070755958557,\n",
              " 0.3045538067817688,\n",
              " 0.3013453185558319,\n",
              " 0.29819396138191223,\n",
              " 0.2950979173183441,\n",
              " 0.29205599427223206,\n",
              " 0.28906673192977905,\n",
              " 0.2861286997795105,\n",
              " 0.2832406163215637,\n",
              " 0.2804013788700104,\n",
              " 0.27760961651802063,\n",
              " 0.27486422657966614,\n",
              " 0.27216413617134094,\n",
              " 0.2695081830024719,\n",
              " 0.2668953835964203,\n",
              " 0.2643246650695801,\n",
              " 0.26179516315460205,\n",
              " 0.25930580496788025,\n",
              " 0.2568557560443878,\n",
              " 0.25444406270980835,\n",
              " 0.2520699203014374,\n",
              " 0.24973240494728088,\n",
              " 0.24743083119392395,\n",
              " 0.24516430497169495,\n",
              " 0.24293215572834015,\n",
              " 0.2407335788011551,\n",
              " 0.23856787383556366,\n",
              " 0.23643434047698975,\n",
              " 0.23433232307434082,\n",
              " 0.23226109147071838,\n",
              " 0.23022010922431946,\n",
              " 0.22820867598056793,\n",
              " 0.22622622549533844,\n",
              " 0.22427213191986084,\n",
              " 0.22234579920768738,\n",
              " 0.22044673562049866,\n",
              " 0.21857433021068573,\n",
              " 0.21672813594341278,\n",
              " 0.21490757167339325,\n",
              " 0.21311213076114655,\n",
              " 0.21134133636951447,\n",
              " 0.2095947265625,\n",
              " 0.20787177979946136,\n",
              " 0.2061721235513687,\n",
              " 0.20449525117874146,\n",
              " 0.20284074544906616,\n",
              " 0.2012081891298294,\n",
              " 0.19959716498851776,\n",
              " 0.19800728559494019,\n",
              " 0.19643811881542206,\n",
              " 0.19488930702209473,\n",
              " 0.19336047768592834,\n",
              " 0.19185130298137665,\n",
              " 0.19036133587360382,\n",
              " 0.18889030814170837,\n",
              " 0.18743781745433807,\n",
              " 0.18600361049175262,\n",
              " 0.1845872849225998,\n",
              " 0.1831885725259781,\n",
              " 0.18180713057518005,\n",
              " 0.1804427057504654,\n",
              " 0.17909492552280426,\n",
              " 0.17776356637477875,\n",
              " 0.1764483004808426,\n",
              " 0.1751488894224167,\n",
              " 0.17386505007743835,\n",
              " 0.1725964993238449,\n",
              " 0.17134295403957367,\n",
              " 0.1701042503118515,\n",
              " 0.16888006031513214,\n",
              " 0.16767020523548126,\n",
              " 0.16647440195083618,\n",
              " 0.1652923822402954,\n",
              " 0.1641240268945694,\n",
              " 0.16296903789043427,\n",
              " 0.1618272066116333,\n",
              " 0.16069833934307098,\n",
              " 0.1595822125673294,\n",
              " 0.15847860276699066,\n",
              " 0.15738733112812042,\n",
              " 0.15630824863910675,\n",
              " 0.15524108707904816,\n",
              " 0.1541856825351715,\n",
              " 0.15314188599586487,\n",
              " 0.15210947394371033,\n",
              " 0.15108828246593475,\n",
              " 0.1500781625509262,\n",
              " 0.14907890558242798,\n",
              " 0.14809036254882812,\n",
              " 0.14711236953735352,\n",
              " 0.1461447924375534,\n",
              " 0.14518745243549347,\n",
              " 0.14424020051956177,\n",
              " 0.14330285787582397,\n",
              " 0.14237532019615173,\n",
              " 0.14145739376544952,\n",
              " 0.14054898917675018,\n",
              " 0.13964994251728058,\n",
              " 0.13876014947891235,\n",
              " 0.13787943124771118,\n",
              " 0.13700765371322632,\n",
              " 0.1361447125673294,\n",
              " 0.1352905035018921,\n",
              " 0.13444484770298004]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjXlXibokhR7",
        "outputId": "9f268fc9-8b3a-45f8-c159-435459afb686"
      },
      "source": [
        "output = model.forward(X, A)\n",
        "test_x = torch.index_select(output, 0, test)\n",
        "test_y = torch.index_select(y, 0, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH4lRMK5nfel"
      },
      "source": [
        "predictions = torch.argmax(test_x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF5S-oX7nicX",
        "outputId": "ba3751d9-bc23-4c1d-93b2-7e1b4508a6f0"
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnvEo5UZnz6F"
      },
      "source": [
        "predictions, test_y = predictions.numpy(), test_y.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQatCg3xn_W1",
        "outputId": "1523c3cc-583f-4651-95fb-78bb88e1782b"
      },
      "source": [
        "acc = 0\n",
        "for i in range(len(test_y)):\n",
        "    if predictions[i] == test_y[i]:\n",
        "        acc += 1\n",
        "ic(acc/len(test_y)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| acc/len(test_y)*100: 76.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.5"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKhTsaydoHlE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}